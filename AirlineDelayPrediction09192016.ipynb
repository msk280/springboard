{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Airline Delays Prediction\"><span style=\"color: #ff0000;\">Atlanta Airport - Airline Departure Delays Prediction</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: left;\">Initialize libraries, get data sets, consolidate and cleanse.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing libraries and the data set\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline \n",
    "plt.rcParams['figure.figsize'] = 12, 4  # that's default image size for this interactive session\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix,  precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "scaler = StandardScaler()\n",
    "from ggplot import *\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be taking 2014 dataset and pick around random 50,000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           int64\n",
       "Unnamed: 0.1         int64\n",
       "FL_DATE             object\n",
       "MONTH                int64\n",
       "DAY_OF_MONTH         int64\n",
       "DAY_OF_WEEK          int64\n",
       "CARRIER             object\n",
       "DEST                object\n",
       "DEP_HOUR           float64\n",
       "DEP_DELAY          float64\n",
       "PRCP               float64\n",
       "SNOW               float64\n",
       "TMAX                 int64\n",
       "TMIN                 int64\n",
       "AWND               float64\n",
       "DEPR_DELAY_FLAG      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATLData2014 = pd.read_csv(\"ATL2014Random.csv\")\n",
    "ATLData2014.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50956, 16)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATLData2014.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #000000;\">Building a Prediction Model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'MONTH','DAY_OF_MONTH','DAY_OF_WEEK','DEP_HOUR','PRCP', 'SNOW', 'TMAX', 'TMIN', 'AWND'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using MONTH with L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision = 0.01, recall = 0.11, F1 = 0.02, accuracy = 0.11\n",
      "\n",
      "Accuracy Score: \n",
      "0.114216186514\n"
     ]
    }
   ],
   "source": [
    "Ycol = 'DEP_DELAY'\n",
    "Xcols = ['MONTH']\n",
    "ATL2014 = pd.read_csv(\"ATL2014Random.csv\")\n",
    "sampled_X = ATL2014[Xcols]\n",
    "sampled_Y = ATL2014[Ycol]\n",
    "# create train and test sets\n",
    "TrainX, TestX, TrainY, TestY  =   train_test_split(sampled_X, sampled_Y, test_size=.5)\n",
    "\n",
    "# logistic regression model creation\n",
    "Create_LR = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\n",
    "Create_LR.fit(TrainX, TrainY)\n",
    "\n",
    "# prediction on test set\n",
    "Predict = Create_LR.predict(TestX)\n",
    "\n",
    "ConfusionMatrix_LR = confusion_matrix(TestY, Predict)\n",
    "# display evaluation metrics\n",
    "report_lr = precision_recall_fscore_support(list(TestY), list(Predict), average='weighted')\n",
    "print \"\\nprecision = %0.2f, recall = %0.2f, F1 = %0.2f, accuracy = %0.2f\\n\" % \\\n",
    "        (report_lr[0], report_lr[1], report_lr[2], accuracy_score(list(TestY), list(Predict)))\n",
    "print 'Accuracy Score: ' \n",
    "print accuracy_score(list(TestY), list(Predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our logistic regression model for MONTH got overall accuracy of 11%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Logistic Regression using DAY_OF_MONTH with L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision = 0.01, recall = 0.11, F1 = 0.02, accuracy = 0.11\n",
      "\n",
      "Accuracy Score: \n",
      "0.110028128475\n"
     ]
    }
   ],
   "source": [
    "Ycol = 'DEP_DELAY'\n",
    "Xcols = ['DAY_OF_MONTH']\n",
    "ATL2014 = pd.read_csv(\"ATL2014Random.csv\")\n",
    "sampled_X = ATL2014[Xcols]\n",
    "sampled_Y = ATL2014[Ycol]\n",
    "# create train and test sets\n",
    "TrainX, TestX, TrainY, TestY  =   train_test_split(sampled_X, sampled_Y, test_size=.3)\n",
    "\n",
    "# logistic regression model creation\n",
    "Create_LR = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\n",
    "Create_LR.fit(TrainX, TrainY)\n",
    "\n",
    "# prediction on test set\n",
    "Predict = Create_LR.predict(TestX)\n",
    "\n",
    "ConfusionMatrix_LR = confusion_matrix(TestY, Predict)\n",
    "# display evaluation metrics\n",
    "report_lr = precision_recall_fscore_support(list(TestY), list(Predict), average='weighted')\n",
    "print \"\\nprecision = %0.2f, recall = %0.2f, F1 = %0.2f, accuracy = %0.2f\\n\" % \\\n",
    "        (report_lr[0], report_lr[1], report_lr[2], accuracy_score(list(TestY), list(Predict)))\n",
    "print 'Accuracy Score: ' \n",
    "print accuracy_score(list(TestY), list(Predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using DAY_OF_WEEK with L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision = 0.01, recall = 0.10, F1 = 0.02, accuracy = 0.10\n",
      "\n",
      "Accuracy Score: \n",
      "0.10486033885\n"
     ]
    }
   ],
   "source": [
    "Ycol = 'DEP_DELAY'\n",
    "Xcols = ['DAY_OF_WEEK']\n",
    "ATL2014 = pd.read_csv(\"ATL2014Random.csv\")\n",
    "sampled_X = ATL2014[Xcols]\n",
    "sampled_Y = ATL2014[Ycol]\n",
    "# create train and test sets\n",
    "TrainX, TestX, TrainY, TestY  =   train_test_split(sampled_X, sampled_Y, test_size=.3)\n",
    "\n",
    "# logistic regression model creation\n",
    "Create_LR = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\n",
    "Create_LR.fit(TrainX, TrainY)\n",
    "\n",
    "# prediction on test set\n",
    "Predict = Create_LR.predict(TestX)\n",
    "\n",
    "ConfusionMatrix_LR = confusion_matrix(TestY, Predict)\n",
    "# display evaluation metrics\n",
    "report_lr = precision_recall_fscore_support(list(TestY), list(Predict), average='weighted')\n",
    "print \"\\nprecision = %0.2f, recall = %0.2f, F1 = %0.2f, accuracy = %0.2f\\n\" % \\\n",
    "        (report_lr[0], report_lr[1], report_lr[2], accuracy_score(list(TestY), list(Predict)))\n",
    "print 'Accuracy Score: ' \n",
    "print accuracy_score(list(TestY), list(Predict))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using DEP_HOUR with L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision = 0.01, recall = 0.11, F1 = 0.02, accuracy = 0.11\n",
      "\n",
      "Accuracy Score: \n",
      "0.10891607248\n"
     ]
    }
   ],
   "source": [
    "Ycol = 'DEP_DELAY'\n",
    "Xcols = ['DEP_HOUR']\n",
    "ATL2014 = pd.read_csv(\"ATL2014Random.csv\")\n",
    "sampled_X = ATL2014[Xcols]\n",
    "sampled_Y = ATL2014[Ycol]\n",
    "# create train and test sets\n",
    "TrainX, TestX, TrainY, TestY  =   train_test_split(sampled_X, sampled_Y, test_size=.3)\n",
    "\n",
    "# logistic regression model creation\n",
    "Create_LR = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\n",
    "Create_LR.fit(TrainX, TrainY)\n",
    "\n",
    "# prediction on test set\n",
    "Predict = Create_LR.predict(TestX)\n",
    "\n",
    "ConfusionMatrix_LR = confusion_matrix(TestY, Predict)\n",
    "# display evaluation metrics\n",
    "report_lr = precision_recall_fscore_support(list(TestY), list(Predict), average='weighted')\n",
    "print \"\\nprecision = %0.2f, recall = %0.2f, F1 = %0.2f, accuracy = %0.2f\\n\" % \\\n",
    "        (report_lr[0], report_lr[1], report_lr[2], accuracy_score(list(TestY), list(Predict)))\n",
    "print 'Accuracy Score: ' \n",
    "print accuracy_score(list(TestY), list(Predict))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using PRCP with L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision = 0.02, recall = 0.11, F1 = 0.03, accuracy = 0.11\n",
      "\n",
      "Accuracy Score: \n",
      "0.108392752012\n"
     ]
    }
   ],
   "source": [
    "Ycol = 'DEP_DELAY'\n",
    "Xcols = ['PRCP']\n",
    "ATL2014 = pd.read_csv(\"ATL2014Random.csv\")\n",
    "sampled_X = ATL2014[Xcols]\n",
    "sampled_Y = ATL2014[Ycol]\n",
    "# create train and test sets\n",
    "TrainX, TestX, TrainY, TestY  =   train_test_split(sampled_X, sampled_Y, test_size=.3)\n",
    "\n",
    "# logistic regression model creation\n",
    "Create_LR = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\n",
    "Create_LR.fit(TrainX, TrainY)\n",
    "\n",
    "# prediction on test set\n",
    "Predict = Create_LR.predict(TestX)\n",
    "\n",
    "ConfusionMatrix_LR = confusion_matrix(TestY, Predict)\n",
    "# display evaluation metrics\n",
    "report_lr = precision_recall_fscore_support(list(TestY), list(Predict), average='weighted')\n",
    "print \"\\nprecision = %0.2f, recall = %0.2f, F1 = %0.2f, accuracy = %0.2f\\n\" % \\\n",
    "        (report_lr[0], report_lr[1], report_lr[2], accuracy_score(list(TestY), list(Predict)))\n",
    "print 'Accuracy Score: ' \n",
    "print accuracy_score(list(TestY), list(Predict))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using SNOW with L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision = 0.01, recall = 0.11, F1 = 0.02, accuracy = 0.11\n",
      "\n",
      "Accuracy Score: \n",
      "0.111728919997\n"
     ]
    }
   ],
   "source": [
    "Ycol = 'DEP_DELAY'\n",
    "Xcols = ['SNOW']\n",
    "ATL2014 = pd.read_csv(\"ATL2014Random.csv\")\n",
    "sampled_X = ATL2014[Xcols]\n",
    "sampled_Y = ATL2014[Ycol]\n",
    "# create train and test sets\n",
    "TrainX, TestX, TrainY, TestY  =   train_test_split(sampled_X, sampled_Y, test_size=.3)\n",
    "\n",
    "# logistic regression model creation\n",
    "Create_LR = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\n",
    "Create_LR.fit(TrainX, TrainY)\n",
    "\n",
    "# prediction on test set\n",
    "Predict = Create_LR.predict(TestX)\n",
    "\n",
    "ConfusionMatrix_LR = confusion_matrix(TestY, Predict)\n",
    "# display evaluation metrics\n",
    "report_lr = precision_recall_fscore_support(list(TestY), list(Predict), average='weighted')\n",
    "print \"\\nprecision = %0.2f, recall = %0.2f, F1 = %0.2f, accuracy = %0.2f\\n\" % \\\n",
    "        (report_lr[0], report_lr[1], report_lr[2], accuracy_score(list(TestY), list(Predict)))\n",
    "print 'Accuracy Score: ' \n",
    "print accuracy_score(list(TestY), list(Predict))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using DEP_DELAY with L1 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using TMAX with L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision = 0.01, recall = 0.11, F1 = 0.02, accuracy = 0.11\n",
      "\n",
      "Accuracy Score: \n",
      "0.114999672925\n"
     ]
    }
   ],
   "source": [
    "Ycol = 'DEP_DELAY'\n",
    "Xcols = ['TMAX']\n",
    "ATL2014 = pd.read_csv(\"ATL2014Random.csv\")\n",
    "sampled_X = ATL2014[Xcols]\n",
    "sampled_Y = ATL2014[Ycol]\n",
    "# create train and test sets\n",
    "TrainX, TestX, TrainY, TestY  =   train_test_split(sampled_X, sampled_Y, test_size=.3)\n",
    "\n",
    "# logistic regression model creation\n",
    "Create_LR = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\n",
    "Create_LR.fit(TrainX, TrainY)\n",
    "\n",
    "# prediction on test set\n",
    "Predict = Create_LR.predict(TestX)\n",
    "\n",
    "ConfusionMatrix_LR = confusion_matrix(TestY, Predict)\n",
    "# display evaluation metrics\n",
    "report_lr = precision_recall_fscore_support(list(TestY), list(Predict), average='weighted')\n",
    "print \"\\nprecision = %0.2f, recall = %0.2f, F1 = %0.2f, accuracy = %0.2f\\n\" % \\\n",
    "        (report_lr[0], report_lr[1], report_lr[2], accuracy_score(list(TestY), list(Predict)))\n",
    "print 'Accuracy Score: ' \n",
    "print accuracy_score(list(TestY), list(Predict))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using TMIN with L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision = 0.01, recall = 0.11, F1 = 0.02, accuracy = 0.11\n",
      "\n",
      "Accuracy Score: \n",
      "0.109243147773\n"
     ]
    }
   ],
   "source": [
    "Ycol = 'DEP_DELAY'\n",
    "Xcols = ['TMIN']\n",
    "ATL2014 = pd.read_csv(\"ATL2014Random.csv\")\n",
    "sampled_X = ATL2014[Xcols]\n",
    "sampled_Y = ATL2014[Ycol]\n",
    "# create train and test sets\n",
    "TrainX, TestX, TrainY, TestY  =   train_test_split(sampled_X, sampled_Y, test_size=.3)\n",
    "\n",
    "# logistic regression model creation\n",
    "Create_LR = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\n",
    "Create_LR.fit(TrainX, TrainY)\n",
    "\n",
    "# prediction on test set\n",
    "Predict = Create_LR.predict(TestX)\n",
    "\n",
    "ConfusionMatrix_LR = confusion_matrix(TestY, Predict)\n",
    "# display evaluation metrics\n",
    "report_lr = precision_recall_fscore_support(list(TestY), list(Predict), average='weighted')\n",
    "print \"\\nprecision = %0.2f, recall = %0.2f, F1 = %0.2f, accuracy = %0.2f\\n\" % \\\n",
    "        (report_lr[0], report_lr[1], report_lr[2], accuracy_score(list(TestY), list(Predict)))\n",
    "print 'Accuracy Score: ' \n",
    "print accuracy_score(list(TestY), list(Predict))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using AWND with L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision = 0.01, recall = 0.11, F1 = 0.02, accuracy = 0.11\n",
      "\n",
      "Accuracy Score: \n",
      "0.107738601426\n"
     ]
    }
   ],
   "source": [
    "Ycol = 'DEP_DELAY'\n",
    "Xcols = ['AWND']\n",
    "ATL2014 = pd.read_csv(\"ATL2014Random.csv\")\n",
    "sampled_X = ATL2014[Xcols]\n",
    "sampled_Y = ATL2014[Ycol]\n",
    "# create train and test sets\n",
    "TrainX, TestX, TrainY, TestY  =   train_test_split(sampled_X, sampled_Y, test_size=.3)\n",
    "\n",
    "# logistic regression model creation\n",
    "Create_LR = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\n",
    "Create_LR.fit(TrainX, TrainY)\n",
    "\n",
    "# prediction on test set\n",
    "Predict = Create_LR.predict(TestX)\n",
    "\n",
    "ConfusionMatrix_LR = confusion_matrix(TestY, Predict)\n",
    "# display evaluation metrics\n",
    "report_lr = precision_recall_fscore_support(list(TestY), list(Predict), average='weighted')\n",
    "print \"\\nprecision = %0.2f, recall = %0.2f, F1 = %0.2f, accuracy = %0.2f\\n\" % \\\n",
    "        (report_lr[0], report_lr[1], report_lr[2], accuracy_score(list(TestY), list(Predict)))\n",
    "print 'Accuracy Score: ' \n",
    "print accuracy_score(list(TestY), list(Predict))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using DEPR_DELAY_FLAG with L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision = 0.02, recall = 0.12, F1 = 0.03, accuracy = 0.12\n",
      "\n",
      "Accuracy Score: \n",
      "0.121606593838\n"
     ]
    }
   ],
   "source": [
    "Ycol = 'DEP_DELAY'\n",
    "Xcols = ['DEPR_DELAY_FLAG']\n",
    "ATL2014 = pd.read_csv(\"ATL2014Random.csv\")\n",
    "sampled_X = ATL2014[Xcols]\n",
    "sampled_Y = ATL2014[Ycol]\n",
    "# create train and test sets\n",
    "TrainX, TestX, TrainY, TestY  =   train_test_split(sampled_X, sampled_Y, test_size=.3)\n",
    "\n",
    "# logistic regression model creation\n",
    "Create_LR = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\n",
    "Create_LR.fit(TrainX, TrainY)\n",
    "\n",
    "# prediction on test set\n",
    "Predict = Create_LR.predict(TestX)\n",
    "\n",
    "ConfusionMatrix_LR = confusion_matrix(TestY, Predict)\n",
    "# display evaluation metrics\n",
    "report_lr = precision_recall_fscore_support(list(TestY), list(Predict), average='weighted')\n",
    "print \"\\nprecision = %0.2f, recall = %0.2f, F1 = %0.2f, accuracy = %0.2f\\n\" % \\\n",
    "        (report_lr[0], report_lr[1], report_lr[2], accuracy_score(list(TestY), list(Predict)))\n",
    "print 'Accuracy Score: ' \n",
    "print accuracy_score(list(TestY), list(Predict))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using All Columns with L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision = 0.05, recall = 0.12, F1 = 0.04, accuracy = 0.12\n",
      "\n",
      "Accuracy Score: \n",
      "0.118401255969\n"
     ]
    }
   ],
   "source": [
    "Ycol = 'DEP_DELAY'\n",
    "Xcols = ['MONTH','DAY_OF_MONTH','DAY_OF_WEEK','DEP_HOUR','PRCP', 'SNOW', 'TMAX', 'TMIN', 'AWND','DEPR_DELAY_FLAG']\n",
    "ATL2014 = pd.read_csv(\"ATL2014Random.csv\")\n",
    "sampled_X = ATL2014[Xcols]\n",
    "sampled_Y = ATL2014[Ycol]\n",
    "# create train and test sets\n",
    "TrainX, TestX, TrainY, TestY  =   train_test_split(sampled_X, sampled_Y, test_size=.3)\n",
    "\n",
    "# logistic regression model creation\n",
    "Create_LR = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\n",
    "Create_LR.fit(TrainX, TrainY)\n",
    "\n",
    "# prediction on test set\n",
    "Predict = Create_LR.predict(TestX)\n",
    "\n",
    "ConfusionMatrix_LR = confusion_matrix(TestY, Predict)\n",
    "# display evaluation metrics\n",
    "report_lr = precision_recall_fscore_support(list(TestY), list(Predict), average='weighted')\n",
    "print \"\\nprecision = %0.2f, recall = %0.2f, F1 = %0.2f, accuracy = %0.2f\\n\" % \\\n",
    "        (report_lr[0], report_lr[1], report_lr[2], accuracy_score(list(TestY), list(Predict)))\n",
    "print 'Accuracy Score: ' \n",
    "print accuracy_score(list(TestY), list(Predict))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLS using All Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25478, 1)\n",
      "(25478, 10)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              DEP_DELAY   R-squared:                       0.065\n",
      "Model:                            OLS   Adj. R-squared:                  0.065\n",
      "Method:                 Least Squares   F-statistic:                     198.2\n",
      "Date:                Sun, 18 Sep 2016   Prob (F-statistic):               0.00\n",
      "Time:                        23:38:55   Log-Likelihood:            -1.2216e+05\n",
      "No. Observations:               25478   AIC:                         2.443e+05\n",
      "Df Residuals:                   25468   BIC:                         2.444e+05\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "--------------------------------------------------------------------------------\n",
      "const            1.7003      1.739      0.977      0.328        -1.709     5.110\n",
      "MONTH           -0.6834      0.056    -12.150      0.000        -0.794    -0.573\n",
      "DAY_OF_MONTH    -0.0999      0.021     -4.772      0.000        -0.141    -0.059\n",
      "DAY_OF_WEEK     -0.4039      0.092     -4.393      0.000        -0.584    -0.224\n",
      "DEP_HOUR         1.1109      0.040     27.784      0.000         1.033     1.189\n",
      "PRCP            14.0682      0.516     27.248      0.000        13.056    15.080\n",
      "SNOW             0.7103      2.309      0.308      0.758        -3.815     5.235\n",
      "TMAX            -0.0582      0.034     -1.693      0.090        -0.126     0.009\n",
      "TMIN             0.0395      0.031      1.268      0.205        -0.022     0.100\n",
      "AWND             0.0262      0.067      0.390      0.697        -0.105     0.158\n",
      "==============================================================================\n",
      "Omnibus:                    29584.189   Durbin-Watson:                   2.003\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          6606717.772\n",
      "Skew:                           5.848   Prob(JB):                         0.00\n",
      "Kurtosis:                      81.017   Cond. No.                     1.21e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.21e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X = sm.add_constant(pd.DataFrame(TrainX, columns=['MONTH','DAY_OF_MONTH','DAY_OF_WEEK','DEP_HOUR','PRCP', 'SNOW', 'TMAX', 'TMIN', 'AWND']))\n",
    "Y = pd.DataFrame(TrainY, columns=['DEP_DELAY'])\n",
    "print Y.shape\n",
    "print X.shape\n",
    "res_full = sm.OLS(Y,X).fit()\n",
    "print res_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
